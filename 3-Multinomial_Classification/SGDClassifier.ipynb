{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Classifier Evaluation\n",
    "## Hyperparameter tuning with grid search and cross-validation\n",
    "<br>\n",
    "## Import Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.term_counter_helper import TermFrequency, TfIdf\n",
    "from utils.data_frame_helper import DataFrameHelper\n",
    "from utils.model_evaluation_helper import ModelEvaluationHelper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  5485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "content = loader.load_data(\"../Data/trainingdata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_names = np.array([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"])\n",
    "df = loader.get_data_frame(content, label_names)\n",
    "df_helper = DataFrameHelper(df, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset in DataFrame Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                               Text\n",
       "0      A  champion products ch approves stock split cham...\n",
       "1      B  computer terminal systems cpml completes sale ...\n",
       "2      A  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3      A  am international inc am nd qtr jan oper shr lo...\n",
       "4      A  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_helper.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "tf = TermFrequency(\n",
    "    label_names,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8,\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "tf.vectorize_corpus(df_helper.raw_text)\n",
    "tf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_model_evaluation = ModelEvaluationHelper(\n",
    "    tf.X, df_helper.y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Hyperparameter Range for Gird Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'alpha': (1e-04, 1e-05, 1e-06),\n",
    "    'penalty': ('l2',  'l1', 'elasticnet'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select SGD Classifier and Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\"linearSVM\", \"logisticRegression\", \"neuralNet\", \"modified_huber\", \"squared_hinge\"]\n",
    "scores = ['precision_weighted', 'recall_weighted', 'f1_weighted', 'auc_roc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn SVM: Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.963\n",
      "Best parameters set:\n",
      "\talpha: 0.0001\n",
      "\tpenalty: 'elasticnet'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.960 (+/-0.008) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.960 (+/-0.018) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.963 (+/-0.013) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.959 (+/-0.005) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.961 (+/-0.013) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.960 (+/-0.013) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.960 (+/-0.011) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.962 (+/-0.012) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.959 (+/-0.013) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       826\n",
      "          1       0.98      0.98      0.98       511\n",
      "          2       0.91      0.94      0.92        63\n",
      "          3       1.00      0.83      0.91        42\n",
      "          4       0.71      0.50      0.59        10\n",
      "          5       0.98      0.98      0.98        83\n",
      "          6       0.85      0.91      0.88        57\n",
      "          7       0.84      0.76      0.80        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "tf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tf_model_evaluation.cross_val_grid_search(\"linearSVM\", \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "tfidf = TfIdf(\n",
    "    label_names,\n",
    "    norm='l2',\n",
    "    smooth_idf = True,\n",
    "    sublinear_tf = False,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8,\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "tfidf.vectorize_corpus(df_helper.raw_text)\n",
    "tfidf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model_evaluation = ModelEvaluationHelper(\n",
    "    tfidf.X, df_helper.y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM: Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.969\n",
      "Best parameters set:\n",
      "\talpha: 0.0001\n",
      "\tpenalty: 'elasticnet'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.968 (+/-0.010) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.964 (+/-0.014) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.969 (+/-0.010) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.966 (+/-0.014) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.963 (+/-0.010) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.965 (+/-0.015) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.960 (+/-0.015) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.964 (+/-0.009) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.964 (+/-0.011) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       826\n",
      "          1       0.96      0.99      0.97       511\n",
      "          2       0.91      0.95      0.93        63\n",
      "          3       0.97      0.88      0.93        42\n",
      "          4       1.00      0.60      0.75        10\n",
      "          5       1.00      0.99      0.99        83\n",
      "          6       0.87      0.84      0.86        57\n",
      "          7       0.80      0.74      0.77        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(\"linearSVM\", \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.970\n",
      "Best parameters set:\n",
      "\talpha: 1e-05\n",
      "\tpenalty: 'l1'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.955 (+/-0.018) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.957 (+/-0.017) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.955 (+/-0.017) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.966 (+/-0.012) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.970 (+/-0.009) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.969 (+/-0.010) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.966 (+/-0.006) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.966 (+/-0.008) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.964 (+/-0.010) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       826\n",
      "          1       0.97      0.98      0.97       511\n",
      "          2       0.89      0.92      0.91        63\n",
      "          3       1.00      0.88      0.94        42\n",
      "          4       1.00      0.60      0.75        10\n",
      "          5       0.99      0.99      0.99        83\n",
      "          6       0.87      0.91      0.89        57\n",
      "          7       0.85      0.74      0.79        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.cross_val_grid_search(\"logisticRegression\", \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected 1-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.967\n",
      "Best parameters set:\n",
      "\talpha: 1e-05\n",
      "\tpenalty: 'l1'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.957 (+/-0.013) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.950 (+/-0.007) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.957 (+/-0.011) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.957 (+/-0.008) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.967 (+/-0.012) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.961 (+/-0.005) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.961 (+/-0.010) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.964 (+/-0.014) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.961 (+/-0.014) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98       826\n",
      "          1       0.97      0.97      0.97       511\n",
      "          2       0.89      0.94      0.91        63\n",
      "          3       1.00      0.86      0.92        42\n",
      "          4       0.88      0.70      0.78        10\n",
      "          5       0.92      0.98      0.95        83\n",
      "          6       0.86      0.84      0.85        57\n",
      "          7       0.78      0.74      0.76        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.cross_val_grid_search(\"neuralNet\", \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
