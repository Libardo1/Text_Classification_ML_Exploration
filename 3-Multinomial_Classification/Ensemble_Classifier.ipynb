{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifiers\n",
    "## Hyperparameter tuning with grid search and cross-validation\n",
    "\n",
    "<img src=\"../images/ensemble.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of **ensemble methods** is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "<br>\n",
    "<br>\n",
    "Two families of ensemble methods are usually distinguished:\n",
    "* In averaging methods, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.\n",
    "    * **Examples: Bagging methods, Forests of randomized trees, ...**\n",
    "* By contrast, in boosting methods, base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.\n",
    "    * **Examples: AdaBoost, Gradient Tree Boosting, ...**\n",
    "\n",
    "## Import Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.term_counter_helper import TermFrequency, TfIdf\n",
    "from utils.data_frame_helper import DataFrameHelper\n",
    "from utils.model_evaluation_helper import ModelEvaluationHelper\n",
    "from utils.classifier_helper import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  5485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "content = loader.load_data(\"../Data/trainingdata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_names = np.array([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"])\n",
    "df = loader.get_data_frame(content, label_names)\n",
    "df_helper = DataFrameHelper(df, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset in DataFrame Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                               Text\n",
       "0      A  champion products ch approves stock split cham...\n",
       "1      B  computer terminal systems cpml completes sale ...\n",
       "2      A  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3      A  am international inc am nd qtr jan oper shr lo...\n",
       "4      A  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_helper.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "tfidf = TfIdf(\n",
    "    label_names,\n",
    "    norm='l2',\n",
    "    smooth_idf = True,\n",
    "    sublinear_tf = False,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8, # 0.5, 0.75, 1.0\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "\n",
    "\n",
    "tfidf.vectorize_corpus(df_helper.raw_text)\n",
    "tfidf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model_evaluation = ModelEvaluationHelper(\n",
    "    tfidf.X, df_helper.y, test_size=0.3, random_state=3, label_names = df_helper.label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "In **random forests**, each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model.\n",
    "<br>\n",
    "<br>\n",
    "This particular implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.\n",
    "\n",
    "<img src=\"../images/RF.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_estimators': (30, 50, 100),\n",
    "    'max_features': (\"sqrt\",\"log2\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "randomForest = clf.multinomial_Ensemble_clf(\"randomForest\", class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   20.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.935\n",
      "Best parameters set:\n",
      "\tmax_features: 'sqrt'\n",
      "\tn_estimators: 100\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.931 (+/-0.020) for {'n_estimators': 30, 'max_features': 'sqrt'}\n",
      "0.929 (+/-0.018) for {'n_estimators': 50, 'max_features': 'sqrt'}\n",
      "0.935 (+/-0.020) for {'n_estimators': 100, 'max_features': 'sqrt'}\n",
      "0.888 (+/-0.033) for {'n_estimators': 30, 'max_features': 'log2'}\n",
      "0.894 (+/-0.028) for {'n_estimators': 50, 'max_features': 'log2'}\n",
      "0.900 (+/-0.030) for {'n_estimators': 100, 'max_features': 'log2'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.96      0.97       826\n",
      "          B       0.89      0.99      0.94       511\n",
      "          C       0.91      0.92      0.91        63\n",
      "          D       0.96      0.64      0.77        42\n",
      "          E       1.00      0.30      0.46        10\n",
      "          F       0.99      0.96      0.98        83\n",
      "          G       0.87      0.84      0.86        57\n",
      "          H       0.90      0.69      0.78        54\n",
      "\n",
      "avg / total       0.95      0.94      0.94      1646\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(randomForest, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extremely Randomized Trees\n",
    "\n",
    "In **extremely randomized trees**, randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremely Randomized Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extraTrees = clf.multinomial_Ensemble_clf(\"extraTrees\", class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   34.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.942\n",
      "Best parameters set:\n",
      "\tmax_features: 'sqrt'\n",
      "\tn_estimators: 100\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.935 (+/-0.020) for {'n_estimators': 30, 'max_features': 'sqrt'}\n",
      "0.941 (+/-0.016) for {'n_estimators': 50, 'max_features': 'sqrt'}\n",
      "0.942 (+/-0.028) for {'n_estimators': 100, 'max_features': 'sqrt'}\n",
      "0.896 (+/-0.023) for {'n_estimators': 30, 'max_features': 'log2'}\n",
      "0.903 (+/-0.024) for {'n_estimators': 50, 'max_features': 'log2'}\n",
      "0.911 (+/-0.019) for {'n_estimators': 100, 'max_features': 'log2'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.97      0.98       826\n",
      "          B       0.92      0.99      0.95       511\n",
      "          C       0.88      0.94      0.91        63\n",
      "          D       1.00      0.79      0.88        42\n",
      "          E       1.00      0.40      0.57        10\n",
      "          F       0.99      0.96      0.98        83\n",
      "          G       0.85      0.82      0.84        57\n",
      "          H       0.92      0.67      0.77        54\n",
      "\n",
      "avg / total       0.96      0.95      0.95      1646\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(extraTrees, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "The core principle of **AdaBoost** is to fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data. The predictions from all of them are then combined through a weighted majority vote (or sum) to produce the final prediction. \n",
    "<br>\n",
    "<br>\n",
    "The data modifications at each so-called boosting iteration consist of applying weights $w_1, w_2, ..., w_N$ to each of the training samples. Initially, those weights are all set to $w_i = 1/N$, so that the first step simply trains a weak learner on the original data. For each successive iteration, the sample weights are individually modified and the learning algorithm is reapplied to the reweighted data.\n",
    "<br>\n",
    "<br>\n",
    "At a given step, those training examples that were incorrectly predicted by the boosted model induced at the previous step have their weights increased, whereas the weights are decreased for those that were predicted correctly. As iterations proceed, examples that are difficult to predict receive ever-increasing influence. Each subsequent weak learner is thereby forced to concentrate on the examples that are missed by the previous ones in the sequence.\n",
    "\n",
    "<img src=\"../images/AB.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adaBoost = clf.multinomial_Ensemble_clf(\"adaBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_estimators': (30, 50, 100),\n",
    "    'learning_rate': (0.1,1.0,5.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.710\n",
      "Best parameters set:\n",
      "\tlearning_rate: 1.0\n",
      "\tn_estimators: 50\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.667 (+/-0.023) for {'learning_rate': 0.1, 'n_estimators': 30}\n",
      "0.672 (+/-0.021) for {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.685 (+/-0.029) for {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.710 (+/-0.077) for {'learning_rate': 1.0, 'n_estimators': 30}\n",
      "0.710 (+/-0.077) for {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.710 (+/-0.076) for {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.453 (+/-0.389) for {'learning_rate': 5.0, 'n_estimators': 30}\n",
      "0.561 (+/-0.220) for {'learning_rate': 5.0, 'n_estimators': 50}\n",
      "0.523 (+/-0.135) for {'learning_rate': 5.0, 'n_estimators': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       1.00      0.73      0.84       826\n",
      "          B       0.57      0.95      0.71       511\n",
      "          C       0.82      0.78      0.80        63\n",
      "          D       0.00      0.00      0.00        42\n",
      "          E       1.00      0.40      0.57        10\n",
      "          F       0.67      0.92      0.78        83\n",
      "          G       0.00      0.00      0.00        57\n",
      "          H       0.00      0.00      0.00        54\n",
      "\n",
      "avg / total       0.75      0.74      0.72      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(adaBoost, \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
