{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Classifiers\n",
    "## Hyperparameter tuning with grid search and cross-validation\n",
    "\n",
    "<img src=\"../images/SGD.jpg\" width=\"500\">\n",
    "\n",
    "**Stochastic Gradient Descent (SGD)** is a simple yet very efficient approach to discriminative learning of linear classifiers under convex loss functions such as (linear) **Support Vector Machines** and **Logistic Regression**. Even though SGD has been around in the machine learning community for a long time, it has received a considerable amount of attention just recently in the context of large-scale learning.\n",
    "<br>\n",
    "<br>\n",
    "SGD has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module easily scale to problems with more than 10^5 training examples and more than 10^5 features.\n",
    "<br>\n",
    "The advantages of Stochastic Gradient Descent are:\n",
    "* Efficiency.\n",
    "* Ease of implementation (lots of opportunities for code tuning).\n",
    "\n",
    "The disadvantages of Stochastic Gradient Descent include:\n",
    "* SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "* SGD is sensitive to feature scaling.\n",
    "\n",
    "## Import Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.term_counter_helper import TermFrequency, TfIdf\n",
    "from utils.data_frame_helper import DataFrameHelper\n",
    "from utils.model_evaluation_helper import ModelEvaluationHelper\n",
    "from utils.classifier_helper import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  5485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "content = loader.load_data(\"../Data/trainingdata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_names = np.array([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"])\n",
    "df = loader.get_data_frame(content, label_names)\n",
    "df_helper = DataFrameHelper(df, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset in DataFrame Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                               Text\n",
       "0      A  champion products ch approves stock split cham...\n",
       "1      B  computer terminal systems cpml completes sale ...\n",
       "2      A  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3      A  am international inc am nd qtr jan oper shr lo...\n",
       "4      A  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_helper.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "tf = TermFrequency(\n",
    "    label_names,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8,\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "tf.vectorize_corpus(df_helper.raw_text)\n",
    "tf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_model_evaluation = ModelEvaluationHelper(\n",
    "    tf.X, df_helper.y, test_size=0.3, random_state=3, label_names = df_helper.label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier Implementation\n",
    "Linear classifiers (SVM, logistic regression, a.o.) with SGD training.\n",
    "<br>\n",
    "This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning, see the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.\n",
    "<br>\n",
    "<br>\n",
    "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Hyperparameter Range for Gird Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'alpha': (1e-04, 1e-05, 1e-06),\n",
    "    'penalty': ('l2',  'l1', 'elasticnet'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select SGD Classifier and Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\"linearSVM\", \"logisticRegression\", \"neuralNet\", \"modified_huber\", \"squared_hinge\"]\n",
    "scores = ['precision_weighted', 'recall_weighted', 'f1_weighted', 'auc_roc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM\n",
    "<img src=\"../images/learnSVM.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "clf = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.961\n",
      "Best parameters set:\n",
      "\talpha: 1e-05\n",
      "\tpenalty: 'elasticnet'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.960 (+/-0.011) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.950 (+/-0.011) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.961 (+/-0.010) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.956 (+/-0.009) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.958 (+/-0.007) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.961 (+/-0.011) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.959 (+/-0.016) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.958 (+/-0.013) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.957 (+/-0.017) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.99      0.99       826\n",
      "          B       0.98      0.98      0.98       511\n",
      "          C       0.89      0.90      0.90        63\n",
      "          D       0.95      0.83      0.89        42\n",
      "          E       0.70      0.70      0.70        10\n",
      "          F       0.95      0.98      0.96        83\n",
      "          G       0.87      0.81      0.84        57\n",
      "          H       0.77      0.87      0.82        54\n",
      "\n",
      "avg / total       0.97      0.96      0.96      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "linearSVM = clf.multinomial_SGD_clf(\n",
    "    \"linearSVM\", n_iter=10, shuffle=True, learning_rate='optimal', class_weight=\"balanced\", average=False)\n",
    "tf_model_evaluation.cross_val_grid_search(linearSVM, \"f1_weighted\", cv = 5, iid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "tfidf = TfIdf(\n",
    "    label_names,\n",
    "    norm='l2',\n",
    "    smooth_idf = True,\n",
    "    sublinear_tf = False,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8,\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "tfidf.vectorize_corpus(df_helper.raw_text)\n",
    "tfidf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model_evaluation = ModelEvaluationHelper(\n",
    "    tfidf.X, df_helper.y, test_size=0.3, random_state=3, label_names = df_helper.label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM: Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.970\n",
      "Best parameters set:\n",
      "\talpha: 0.0001\n",
      "\tpenalty: 'l2'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.970 (+/-0.009) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.961 (+/-0.013) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.968 (+/-0.010) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.966 (+/-0.014) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.963 (+/-0.015) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.965 (+/-0.004) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.964 (+/-0.009) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.958 (+/-0.010) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.960 (+/-0.012) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.98      0.99       826\n",
      "          B       0.96      0.99      0.97       511\n",
      "          C       0.91      0.95      0.93        63\n",
      "          D       0.97      0.88      0.93        42\n",
      "          E       1.00      0.70      0.82        10\n",
      "          F       0.98      0.99      0.98        83\n",
      "          G       0.83      0.88      0.85        57\n",
      "          H       0.85      0.74      0.79        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "\n",
    "linearSVM = clf.multinomial_SGD_clf(\n",
    "    \"linearSVM\", n_iter=10, shuffle=True, learning_rate='optimal', class_weight=\"balanced\", average=False)\n",
    "tfidf_model_evaluation.cross_val_grid_search(linearSVM, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function.\n",
    "<br>\n",
    "<br>\n",
    "This implementation can fit a multiclass (one-vs-rest) logistic regression with optional L2 or L1 regularization.\n",
    "<br>\n",
    "<br>\n",
    "As an optimization problem, binary class $L2$ penalized logistic regression minimizes the following cost function:\n",
    "$$\\underset{w, c}{min\\,} \\frac{1}{2}w^T w + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1) .$$\n",
    "Similarly, $L1$ regularized logistic regression solves the following optimization problem\n",
    "$$\\underset{w, c}{min\\,} \\|w\\|_1 + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1) .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.970\n",
      "Best parameters set:\n",
      "\talpha: 1e-05\n",
      "\tpenalty: 'elasticnet'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.959 (+/-0.015) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.957 (+/-0.008) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.960 (+/-0.017) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.968 (+/-0.012) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.969 (+/-0.009) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.970 (+/-0.008) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.965 (+/-0.016) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.961 (+/-0.011) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.966 (+/-0.014) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.98      0.99       826\n",
      "          B       0.95      0.99      0.97       511\n",
      "          C       0.88      0.97      0.92        63\n",
      "          D       0.97      0.86      0.91        42\n",
      "          E       0.86      0.60      0.71        10\n",
      "          F       1.00      0.99      0.99        83\n",
      "          G       0.85      0.89      0.87        57\n",
      "          H       0.87      0.74      0.80        54\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "logisticRegression = clf.multinomial_SGD_clf(\n",
    "    \"logisticRegression\", n_iter=10, shuffle=True, learning_rate='optimal', class_weight=\"balanced\", average=False)\n",
    "tfidf_model_evaluation.cross_val_grid_search(logisticRegression, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "The Perceptron is another simple algorithm suitable for large scale learning.\n",
    "By default:\n",
    "* It does not require a learning rate.\n",
    "* It is not regularized (penalized).\n",
    "* It updates its model only on mistakes.\n",
    "\n",
    "The last characteristic implies that the Perceptron is slightly faster to train than SGD with the hinge loss and that the resulting models are sparser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.962\n",
      "Best parameters set:\n",
      "\talpha: 1e-05\n",
      "\tpenalty: 'l2'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.956 (+/-0.014) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.911 (+/-0.035) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.947 (+/-0.014) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.962 (+/-0.009) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.955 (+/-0.009) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.960 (+/-0.010) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.956 (+/-0.008) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.962 (+/-0.007) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.960 (+/-0.009) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.98      0.98      0.98       826\n",
      "          B       0.96      0.97      0.97       511\n",
      "          C       0.92      0.90      0.91        63\n",
      "          D       0.97      0.81      0.88        42\n",
      "          E       0.67      0.60      0.63        10\n",
      "          F       0.96      0.99      0.98        83\n",
      "          G       0.84      0.91      0.87        57\n",
      "          H       0.91      0.80      0.85        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "perceptron = clf.multinomial_SGD_clf(\n",
    "    \"perceptron\", n_iter=10, shuffle=True, learning_rate='optimal', class_weight=\"balanced\", average=False)\n",
    "tfidf_model_evaluation.cross_val_grid_search(perceptron, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Huber Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.964\n",
      "Best parameters set:\n",
      "\talpha: 0.0001\n",
      "\tpenalty: 'elasticnet'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.962 (+/-0.011) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.956 (+/-0.009) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.964 (+/-0.011) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.958 (+/-0.013) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.955 (+/-0.007) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.957 (+/-0.020) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.964 (+/-0.008) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.958 (+/-0.013) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.961 (+/-0.013) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.98      0.99       826\n",
      "          B       0.95      0.99      0.97       511\n",
      "          C       0.86      0.95      0.90        63\n",
      "          D       1.00      0.83      0.91        42\n",
      "          E       1.00      0.50      0.67        10\n",
      "          F       1.00      0.99      0.99        83\n",
      "          G       0.90      0.81      0.85        57\n",
      "          H       0.89      0.72      0.80        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "modified_huber = clf.multinomial_SGD_clf(\n",
    "    \"modified_huber\", n_iter=10, shuffle=True, learning_rate='optimal', class_weight=\"balanced\", average=False)\n",
    "tfidf_model_evaluation.cross_val_grid_search(modified_huber, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squared Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score: 0.957\n",
      "Best parameters set:\n",
      "\talpha: 1e-06\n",
      "\tpenalty: 'elasticnet'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.931 (+/-0.016) for {'penalty': 'l2', 'alpha': 0.0001}\n",
      "0.939 (+/-0.006) for {'penalty': 'l1', 'alpha': 0.0001}\n",
      "0.939 (+/-0.015) for {'penalty': 'elasticnet', 'alpha': 0.0001}\n",
      "0.939 (+/-0.013) for {'penalty': 'l2', 'alpha': 1e-05}\n",
      "0.940 (+/-0.007) for {'penalty': 'l1', 'alpha': 1e-05}\n",
      "0.939 (+/-0.011) for {'penalty': 'elasticnet', 'alpha': 1e-05}\n",
      "0.955 (+/-0.013) for {'penalty': 'l2', 'alpha': 1e-06}\n",
      "0.953 (+/-0.008) for {'penalty': 'l1', 'alpha': 1e-06}\n",
      "0.957 (+/-0.012) for {'penalty': 'elasticnet', 'alpha': 1e-06}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.98      0.98      0.98       826\n",
      "          B       0.98      0.97      0.97       511\n",
      "          C       0.92      0.94      0.93        63\n",
      "          D       0.87      0.81      0.84        42\n",
      "          E       0.50      0.70      0.58        10\n",
      "          F       0.96      0.98      0.97        83\n",
      "          G       0.84      0.84      0.84        57\n",
      "          H       0.86      0.80      0.83        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "squared_hinge = clf.multinomial_SGD_clf(\n",
    "    \"squared_hinge\", n_iter=10, shuffle=True, learning_rate='optimal', class_weight=\"balanced\", average=False)\n",
    "tfidf_model_evaluation.cross_val_grid_search(squared_hinge, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
