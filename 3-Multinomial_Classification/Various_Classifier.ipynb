{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Classifier Evaluation\n",
    "## Hyperparameter tuning with grid search and cross-validation\n",
    "<br>\n",
    "## Import Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.term_counter_helper import TermFrequency, TfIdf\n",
    "from utils.data_frame_helper import DataFrameHelper\n",
    "from utils.model_evaluation_helper import ModelEvaluationHelper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  5485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "content = loader.load_data(\"../Data/trainingdata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_names = np.array([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"])\n",
    "df = loader.get_data_frame(content, label_names)\n",
    "df_helper = DataFrameHelper(df, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset in DataFrame Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                               Text\n",
       "0      A  champion products ch approves stock split cham...\n",
       "1      B  computer terminal systems cpml completes sale ...\n",
       "2      A  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3      A  am international inc am nd qtr jan oper shr lo...\n",
       "4      A  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_helper.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Hyperparameter Range for Gird Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select SGD Classifier and Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\"linearSVM\", \"logisticRegression\", \"neuralNet\", \"modified_huber\", \"squared_hinge\"]\n",
    "scores = ['precision_weighted', 'recall_weighted', 'f1_weighted', 'auc_roc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "# tfidf = TfIdf(\n",
    "#     label_names,\n",
    "#     norm='l2',\n",
    "#     smooth_idf = True,\n",
    "#     sublinear_tf = False,\n",
    "#     lowercase=True,\n",
    "#     preprocessor=None,\n",
    "#     tokenizer=None,\n",
    "#     stop_words='english',\n",
    "#     ngram_range=(1, 1),\n",
    "#     analyzer='word',\n",
    "#     max_df=0.8, # 0.5, 0.75, 1.0\n",
    "#     min_df = min_df,\n",
    "#     max_features=None,\n",
    "#     vocabulary=None)\n",
    "\n",
    "## Change to TF!\n",
    "tfidf = TermFrequency(\n",
    "    label_names,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8,\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "tfidf.vectorize_corpus(df_helper.raw_text)\n",
    "tfidf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model_evaluation = ModelEvaluationHelper(\n",
    "    tfidf.X, df_helper.y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'alpha': (1.0, .1, .01, .001),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM: Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best score: 0.945\n",
      "Best parameters set:\n",
      "\talpha: 1.0\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.945 (+/-0.019) for {'alpha': 1.0}\n",
      "0.943 (+/-0.018) for {'alpha': 0.1}\n",
      "0.939 (+/-0.023) for {'alpha': 0.01}\n",
      "0.931 (+/-0.025) for {'alpha': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.96      0.97       826\n",
      "          1       0.93      0.97      0.95       511\n",
      "          2       0.75      0.89      0.81        63\n",
      "          3       1.00      0.79      0.88        42\n",
      "          4       0.60      0.30      0.40        10\n",
      "          5       0.95      0.96      0.96        83\n",
      "          6       0.85      0.79      0.82        57\n",
      "          7       0.70      0.78      0.74        54\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(\"multinomialNB\", \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best score: 0.892\n",
      "Best parameters set:\n",
      "\talpha: 0.001\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.799 (+/-0.023) for {'alpha': 1.0}\n",
      "0.878 (+/-0.017) for {'alpha': 0.1}\n",
      "0.891 (+/-0.021) for {'alpha': 0.01}\n",
      "0.892 (+/-0.026) for {'alpha': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95       826\n",
      "          1       0.89      0.92      0.91       511\n",
      "          2       0.62      0.71      0.67        63\n",
      "          3       0.97      0.71      0.82        42\n",
      "          4       1.00      0.30      0.46        10\n",
      "          5       0.92      0.88      0.90        83\n",
      "          6       0.74      0.70      0.72        57\n",
      "          7       0.64      0.59      0.62        54\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_evaluation.cross_val_grid_search(\"bernoulliNB\", \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 100 best features by a chi-squared test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute chi-squared stats between each non-negative feature and class.\n",
    "Recall that the chi-square test measures dependence between stochastic variables,\n",
    "so using this function “weeds out” the features that are the most likely to be independent\n",
    "of class and therefore irrelevant for classification.\n",
    "\"\"\"\n",
    "feature_names = tfidf.vectorizer.get_feature_names()\n",
    "select_chi2 = 100\n",
    "print(\"Extracting %d best features by a chi-squared test\" %\n",
    "      select_chi2)\n",
    "ch2 = SelectKBest(chi2, k=select_chi2)\n",
    "X_train = ch2.fit_transform(tfidf_model_evaluation.X_train, tfidf_model_evaluation.y_train)\n",
    "X_test = ch2.transform(tfidf_model_evaluation.X_test)\n",
    "\n",
    "# keep selected feature names\n",
    "feature_names = np.asarray([feature_names[i] for i in ch2.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"multinomialNB\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
