{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Classifier Evaluation\n",
    "## Hyperparameter tuning with grid search and cross-validation\n",
    "<br>\n",
    "## Import Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Utility Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.term_counter_helper import TermFrequency, TfIdf\n",
    "from utils.data_frame_helper import DataFrameHelper\n",
    "from utils.model_evaluation_helper import ModelEvaluationHelper\n",
    "from utils.classifier_helper import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  5485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "content = loader.load_data(\"../Data/trainingdata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_names = np.array([\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"])\n",
    "df = loader.get_data_frame(content, label_names)\n",
    "df_helper = DataFrameHelper(df, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Dataset in DataFrame Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                               Text\n",
       "0      A  champion products ch approves stock split cham...\n",
       "1      B  computer terminal systems cpml completes sale ...\n",
       "2      A  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3      A  am international inc am nd qtr jan oper shr lo...\n",
       "4      A  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_helper.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Hyperparameter Range for Gird Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select SGD Classifier and Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\"linearSVM\", \"logisticRegression\", \"neuralNet\", \"modified_huber\", \"squared_hinge\"]\n",
    "scores = ['precision_weighted', 'recall_weighted', 'f1_weighted', 'auc_roc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "# Change to TF!\n",
    "tf = TermFrequency(\n",
    "    label_names,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8,\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "tf.vectorize_corpus(df_helper.raw_text)\n",
    "tf.vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_model_evaluation = ModelEvaluationHelper(\n",
    "    tf.X, df_helper.y, test_size=0.3, random_state=3, label_names = df_helper.label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'alpha': (1.0, .1, .01, .001),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "multinomialNB = clf.multinomial_NB_clf(\"multinomialNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best score: 0.945\n",
      "Best parameters set:\n",
      "\talpha: 1.0\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.945 (+/-0.019) for {'alpha': 1.0}\n",
      "0.943 (+/-0.018) for {'alpha': 0.1}\n",
      "0.939 (+/-0.023) for {'alpha': 0.01}\n",
      "0.931 (+/-0.025) for {'alpha': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.96      0.97       826\n",
      "          B       0.93      0.97      0.95       511\n",
      "          C       0.75      0.89      0.81        63\n",
      "          D       1.00      0.79      0.88        42\n",
      "          E       0.60      0.30      0.40        10\n",
      "          F       0.95      0.96      0.96        83\n",
      "          G       0.85      0.79      0.82        57\n",
      "          H       0.70      0.78      0.74        54\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "tf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tf_model_evaluation.cross_val_grid_search(multinomialNB, \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best score: 0.892\n",
      "Best parameters set:\n",
      "\talpha: 0.001\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.799 (+/-0.023) for {'alpha': 1.0}\n",
      "0.878 (+/-0.017) for {'alpha': 0.1}\n",
      "0.891 (+/-0.021) for {'alpha': 0.01}\n",
      "0.892 (+/-0.026) for {'alpha': 0.001}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.94      0.95      0.95       826\n",
      "          B       0.89      0.92      0.91       511\n",
      "          C       0.62      0.71      0.67        63\n",
      "          D       0.97      0.71      0.82        42\n",
      "          E       1.00      0.30      0.46        10\n",
      "          F       0.92      0.88      0.90        83\n",
      "          G       0.74      0.70      0.72        57\n",
      "          H       0.64      0.59      0.62        54\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "bernoulliNB = clf.multinomial_NB_clf(\"bernoulliNB\")\n",
    "tf_model_evaluation.cross_val_grid_search(bernoulliNB, \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.8, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = 2\n",
    "\n",
    "tfidf = TfIdf(\n",
    "    label_names,\n",
    "    norm='l2',\n",
    "    smooth_idf = True,\n",
    "    sublinear_tf = False,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=0.8, # 0.5, 0.75, 1.0\n",
    "    min_df = min_df,\n",
    "    max_features=None,\n",
    "    vocabulary=None)\n",
    "\n",
    "\n",
    "\n",
    "tfidf.vectorize_corpus(df_helper.raw_text)\n",
    "tfidf.vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Trainset and Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_model_evaluation = ModelEvaluationHelper(\n",
    "    tfidf.X, df_helper.y, test_size=0.3, random_state=3, label_names = df_helper.label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'n_neighbors': (2, 5),\n",
    "    'weights': (\"uniform\", \"distance\"),\n",
    "    'metric': (\"cosine\", \"euclidean\", \"minkowski\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:   16.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.914\n",
      "Best parameters set:\n",
      "\tmetric: 'euclidean'\n",
      "\tn_neighbors: 5\n",
      "\tweights: 'distance'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.853 (+/-0.023) for {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'cosine'}\n",
      "0.877 (+/-0.035) for {'n_neighbors': 2, 'weights': 'distance', 'metric': 'cosine'}\n",
      "0.905 (+/-0.010) for {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'cosine'}\n",
      "0.903 (+/-0.018) for {'n_neighbors': 5, 'weights': 'distance', 'metric': 'cosine'}\n",
      "0.853 (+/-0.023) for {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "0.889 (+/-0.027) for {'n_neighbors': 2, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "0.905 (+/-0.011) for {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "0.914 (+/-0.010) for {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "0.853 (+/-0.023) for {'n_neighbors': 2, 'weights': 'uniform', 'metric': 'minkowski'}\n",
      "0.889 (+/-0.027) for {'n_neighbors': 2, 'weights': 'distance', 'metric': 'minkowski'}\n",
      "0.905 (+/-0.011) for {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'minkowski'}\n",
      "0.914 (+/-0.010) for {'n_neighbors': 5, 'weights': 'distance', 'metric': 'minkowski'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.90      0.98      0.94       826\n",
      "          B       0.96      0.85      0.90       511\n",
      "          C       0.77      0.89      0.82        63\n",
      "          D       0.94      0.74      0.83        42\n",
      "          E       0.86      0.60      0.71        10\n",
      "          F       0.93      0.93      0.93        83\n",
      "          G       0.85      0.79      0.82        57\n",
      "          H       0.77      0.67      0.71        54\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1646\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# weights: uniform\", \"distance\"\n",
    "# metric: “euclidean”, “manhattan”, “chebyshev”, “minkowski”, “wminkowski”, “seuclidean”, “mahalanobis”\n",
    "\n",
    "knn = clf.multinomial_neighbors_clf(\"KNN\")#, n_neighbors=5, weights=\"distance\", metric=\"minkowski\")\n",
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(knn, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'metric': (\"cosine\", \"euclidean\",\"l2\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.861\n",
      "Best parameters set:\n",
      "\tmetric: 'cosine'\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.861 (+/-0.018) for {'metric': 'cosine'}\n",
      "0.815 (+/-0.029) for {'metric': 'euclidean'}\n",
      "0.815 (+/-0.029) for {'metric': 'l2'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       1.00      0.82      0.90       826\n",
      "          B       0.79      0.96      0.87       511\n",
      "          C       0.88      0.97      0.92        63\n",
      "          D       0.89      0.81      0.85        42\n",
      "          E       0.62      1.00      0.77        10\n",
      "          F       0.88      0.99      0.93        83\n",
      "          G       0.68      0.93      0.79        57\n",
      "          H       0.78      0.72      0.75        54\n",
      "\n",
      "avg / total       0.90      0.88      0.88      1646\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.2s finished\n",
      "/Users/marvin/anaconda2/envs/Notebook-env/lib/python3.5/site-packages/sklearn/neighbors/nearest_centroid.py:138: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    }
   ],
   "source": [
    "# ‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’, ‘manhattan’\n",
    "NearestCentroid = clf.multinomial_neighbors_clf(\"NearestCentroid\")#, n_neighbors=5, weights=\"distance\", metric=\"minkowski\")\n",
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(NearestCentroid, \"f1_weighted\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {'gamma': [1e-1, 1e-2],\n",
    "                   'C': [100, 1000, 10000]\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.963\n",
      "Best parameters set:\n",
      "\tC: 1000\n",
      "\tgamma: 0.1\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.962 (+/-0.014) for {'gamma': 0.1, 'C': 100}\n",
      "0.957 (+/-0.013) for {'gamma': 0.01, 'C': 100}\n",
      "0.963 (+/-0.013) for {'gamma': 0.1, 'C': 1000}\n",
      "0.962 (+/-0.014) for {'gamma': 0.01, 'C': 1000}\n",
      "0.963 (+/-0.013) for {'gamma': 0.1, 'C': 10000}\n",
      "0.962 (+/-0.013) for {'gamma': 0.01, 'C': 10000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.98      0.98      0.98       826\n",
      "          B       0.94      0.99      0.96       511\n",
      "          C       0.91      0.94      0.92        63\n",
      "          D       1.00      0.81      0.89        42\n",
      "          E       1.00      0.40      0.57        10\n",
      "          F       1.00      0.99      0.99        83\n",
      "          G       0.87      0.82      0.85        57\n",
      "          H       0.85      0.72      0.78        54\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1646\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussianSVM = clf.multinomial_SVM_clf(\"gaussianSVM\", class_weight='balanced', degree=3, shrinking=True, probability=False)\n",
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(gaussianSVM, \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.812\n",
      "Best parameters set:\n",
      "\tC: 10000\n",
      "\tgamma: 0.1\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.477 (+/-0.189) for {'gamma': 0.1, 'C': 100}\n",
      "0.089 (+/-0.194) for {'gamma': 0.01, 'C': 100}\n",
      "0.681 (+/-0.031) for {'gamma': 0.1, 'C': 1000}\n",
      "0.185 (+/-0.388) for {'gamma': 0.01, 'C': 1000}\n",
      "0.812 (+/-0.028) for {'gamma': 0.1, 'C': 10000}\n",
      "0.092 (+/-0.190) for {'gamma': 0.01, 'C': 10000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full train set with cross-validation.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.98      0.91      0.95       826\n",
      "          B       0.66      0.99      0.79       511\n",
      "          C       1.00      0.46      0.63        63\n",
      "          D       1.00      0.17      0.29        42\n",
      "          E       1.00      0.10      0.18        10\n",
      "          F       1.00      0.42      0.59        83\n",
      "          G       0.84      0.37      0.51        57\n",
      "          H       0.94      0.30      0.45        54\n",
      "\n",
      "avg / total       0.88      0.83      0.82      1646\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "polynomialSVM = clf.multinomial_SVM_clf(\"polynomialSVM\", class_weight='balanced', degree=3, shrinking=True, probability=False)\n",
    "tfidf_model_evaluation.set_hyperparam_grid(hyperparameters)\n",
    "tfidf_model_evaluation.cross_val_grid_search(polynomialSVM, \"accuracy\", cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM: Run Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 100 best features by a chi-squared test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SelectKBest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d3a3dc15a7dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m print(\"Extracting %d best features by a chi-squared test\" %\n\u001b[1;32m     10\u001b[0m       select_chi2)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_chi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_model_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_model_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_model_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SelectKBest' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compute chi-squared stats between each non-negative feature and class.\n",
    "Recall that the chi-square test measures dependence between stochastic variables,\n",
    "so using this function “weeds out” the features that are the most likely to be independent\n",
    "of class and therefore irrelevant for classification.\n",
    "\"\"\"\n",
    "feature_names = tfidf.vectorizer.get_feature_names()\n",
    "select_chi2 = 100\n",
    "print(\"Extracting %d best features by a chi-squared test\" %\n",
    "      select_chi2)\n",
    "ch2 = SelectKBest(chi2, k=select_chi2)\n",
    "X_train = ch2.fit_transform(tfidf_model_evaluation.X_train, tfidf_model_evaluation.y_train)\n",
    "X_test = ch2.transform(tfidf_model_evaluation.X_test)\n",
    "\n",
    "# keep selected feature names\n",
    "feature_names = np.asarray([feature_names[i] for i in ch2.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"multinomialNB\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
